<script lang="ts" setup>
import { defineEmits, ref } from 'vue'
import ChatService from '@/api/chat'

const emit = defineEmits(['transcript'])

const isRecording = ref(false)
let mediaRecorder: MediaRecorder | null = null
let audioChunks: BlobPart[] = []

// å¼€å§‹å½•éŸ³
async function startRecording() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    mediaRecorder = new MediaRecorder(stream)

    audioChunks = []
    mediaRecorder.ondataavailable = (event: BlobEvent) => {
      if (event.data.size > 0) {
        audioChunks.push(event.data)
      }
    }

    mediaRecorder.start()
    isRecording.value = true
    console.log('ðŸŽ™ å¼€å§‹å½•éŸ³...')
  }
  catch (err) {
    console.error('å½•éŸ³å¤±è´¥:', err)
    alert('æ— æ³•èŽ·å–éº¦å…‹é£Žæƒé™')
  }
}

// åœæ­¢å½•éŸ³å¹¶ä¸Šä¼ 
async function stopRecording() {
  if (!mediaRecorder)
    return

  mediaRecorder.stop()
  isRecording.value = false

  mediaRecorder.onstop = async () => {
    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' })
    const file = new File([audioBlob], 'record.webm', { type: 'audio/webm' })

    const formData = new FormData()
    formData.append('file', file)

    try {
      const response: any = await ChatService.transcriptions(formData)
      emit('transcript', response.asr_text || '')
    }
    catch (err) {
      console.error('ä¸Šä¼ å¤±è´¥:', err)
    }
  }
}
</script>

<template>
  <div class="record-audio">
    <img v-if="!isRecording" alt="" src="@/assets/voiceStart.png" @click="startRecording">
    <img v-if="isRecording" alt="" src="@/assets/voiceStop.png" @click="stopRecording">
  </div>
</template>

<style scoped>
.record-audio {
  width: 40px;
  height: 40px;
  display: flex;
  align-items: center;
  justify-content: center;
  background: #c5dcf5;
  border-radius: 50%;
  position: fixed;
  top: 170px;
  left: 10px;
  z-index: 99;
}
</style>
