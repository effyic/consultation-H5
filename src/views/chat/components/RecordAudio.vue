<template>
  <div class="record-audio">
    <img v-if="!isRecording" alt="" src="@/assets/voiceStart.png" @click="startRecording">
    <img v-if="isRecording" alt="" src="@/assets/voiceStop.png" @click="stopRecording">
  </div>
</template>

<script lang="ts" setup>
import { ref, defineEmits } from "vue";
import ChatService from '@/api/chat'

const emit = defineEmits(['transcript']);

const isRecording = ref(false);
let mediaRecorder: MediaRecorder | null = null;
let audioChunks: BlobPart[] = [];

// å¼€å§‹å½•éŸ³
const startRecording = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream);

    audioChunks = [];
    mediaRecorder.ondataavailable = (event: BlobEvent) => {
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };

    mediaRecorder.start();
    isRecording.value = true;
    console.log("ðŸŽ™ å¼€å§‹å½•éŸ³...");
  } catch (err) {
    console.error("å½•éŸ³å¤±è´¥:", err);
    alert("æ— æ³•èŽ·å–éº¦å…‹é£Žæƒé™");
  }
};

// åœæ­¢å½•éŸ³å¹¶ä¸Šä¼ 
const stopRecording = async () => {
  if (!mediaRecorder) return;

  mediaRecorder.stop();
  isRecording.value = false;

  mediaRecorder.onstop = async () => {
    const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
    const file = new File([audioBlob], "record.webm", { type: "audio/webm" });

    const formData = new FormData();
    formData.append("file", file);

    try {
      const response: any = await ChatService.transcriptions(formData);
      emit('transcript', response.asr_text || '');
    } catch (err) {
      console.error("ä¸Šä¼ å¤±è´¥:", err);
    }
  };
};
</script>

<style scoped>
.record-audio {
  width: 40px;
  height: 40px;
  display: flex;
  align-items: center;
  justify-content: center;
  background: #c5dcf5;
  border-radius: 50%;
  position: fixed;
  top: 170px;
  left: 10px;
  z-index: 99;
}
</style>
